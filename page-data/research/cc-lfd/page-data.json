{"componentChunkName":"component---src-templates-blog-post-js","path":"/research/cc-lfd/","result":{"data":{"markdownRemark":{"id":"fdc4f90d-32ea-59c4-9749-1e36e6f5d2fa","html":"<h2>Why is this important?</h2>\n<p>My PhD research’s seminal work is called <strong>Concept Constrained Learning from Demonstration</strong> <span id=\"citation-0\" data-hover=\"\"><span class=\"citation-number\">[1]</span></span>. It is this work that motivates my current research into constrained motion planning and human-robot interfaces, specifically augmented reality interfaces. Ultimately, I want to figure out how to make robots easily trainable and usable by non-roboticists. Physical automation is a wide-open frontier in the world of information technology. However, the introduction of collaborative robots into human environments presents a number of challenges often not required of large-scale industrial robots: safety in shared workspaces, rapidly changing task requirements, decision-making, and, perhaps most challenging, adhering to human expectations of behavior. As such, the foundational motivation behind this work is to provide human users the means to easily train collaborative robots to execute dynamic skills while adhering to important behavioral restrictions.</p>\n<h2>Background</h2>\n<h3>Learning from Demonstration</h3>\n<p>Robot Learning from Demonstration (LfD) consists of methods that attempt to learn successful robot behavior models from human input. A human operator interacts with a robotic system through some mode of demonstration, usually through kinesthetic demonstration (e.g. physical interaction), teleoperation (e.g. remote control), or passive observation (e.g. motion tracking observation). Demonstration ideally communicates information about the nature of the skill that the robotic learning system uses to build a learned model that resembles some latent (i.e. hidden) ground truth model. The methods by which robotic systems learn such models spans across the spectrum of machine learning. However there are three broad cateogrizations for robot LfD systems: 1) plan learning, 2) functional optimization, and 3) policy learning  <span id=\"citation-0\" data-hover=\"\"><span class=\"citation-number\">[2]</span></span>.</p>\n<p><figure><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 450px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4d3b3c608170205bce549ef23656749a/3acf0/ActionShot.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.75221238938053%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMCBP/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABtKW805h//8QAHBAAAgEFAQAAAAAAAAAAAAAAAgMTAAEREiIy/9oACAEBAAEFAm9U8hiWBajfLHAMI+f/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8Bka//xAAWEQADAAAAAAAAAAAAAAAAAAAAARH/2gAIAQIBAT8BbhD/xAAaEAACAwEBAAAAAAAAAAAAAAAAAQIRIRKh/9oACAEBAAY/AuBQXpsRpl1tCP/EABwQAQACAgMBAAAAAAAAAAAAAAEAESExQVGBsf/aAAgBAQABPyF0e0cvqvEZZ8uKOIzywv5GW6GY3cmJ/9oADAMBAAIAAwAAABBrH//EABcRAAMBAAAAAAAAAAAAAAAAAAABEVH/2gAIAQMBAT8QoqRh/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERQf/aAAgBAgEBPxC6Dd6f/8QAGxABAAMBAAMAAAAAAAAAAAAAAQARIVExQXH/2gAIAQEAAT8QoIrI6/dm3J2eB18seg2Oo4qsj4hVOagPkRT1DGABg1P/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"ActionShot\"\n        title=\"ActionShot\"\n        src=\"/static/4d3b3c608170205bce549ef23656749a/20e5d/ActionShot.jpg\"\n        srcset=\"/static/4d3b3c608170205bce549ef23656749a/30b1b/ActionShot.jpg 113w,\n/static/4d3b3c608170205bce549ef23656749a/863e1/ActionShot.jpg 225w,\n/static/4d3b3c608170205bce549ef23656749a/20e5d/ActionShot.jpg 450w,\n/static/4d3b3c608170205bce549ef23656749a/512c0/ActionShot.jpg 675w,\n/static/4d3b3c608170205bce549ef23656749a/8e1fc/ActionShot.jpg 900w,\n/static/4d3b3c608170205bce549ef23656749a/3acf0/ActionShot.jpg 2000w\"\n        sizes=\"(max-width: 450px) 100vw, 450px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span><figcaption>A human user (me) kinestheticaly demonstrating a skill.</figcaption></figure></p>\n<p>The ultimate goal of these learning methods is to facilitate the transfer of information from a non-roboticist, with some expert intuition about the skill, to the robotic learning system. This information is then used by robot skill learning methods to produce successful learned models of the task. Plan learning methods attempt to learn models that operate at high levels of task abstraction, either learning a primitive sequence or hierarchy. Functional optimization methods either directly optimize a candidate trajectory (potentially one derived from demonstration) using a known objective function, or they attempt to learn an objective from demonstration. These approaches often emulate or directly draw from Reinforcement Learning and Inverse Reinforcement Learning techniques. Lastly, policy learning methods produce models that output either trajectories or low-level actions directly.</p>\n<h3>Keyframe Learning from Demonstration</h3>\n<p>CC-LfD is an augnmentation of a learning method called Keyframe LfD (KLfD) <span id=\"citation-0\" data-hover=\"\"><span class=\"citation-number\">[3]</span></span>. In traditional KLfD, human operators teach a skill by providing distinct waypoints of robot state data. This represents a coarse trajectory for the robot to follow. This approach is powerful because it very easily allows users to specify robot motion, but it is somewhat brittle as the learned skill is really a concrete instantiation of one robot trajectory. Any variation to the environment or to changes in user expecations cannot be accomodated.</p>\n<p>Keyframe LfD can be make more robust through automating keyframe generation and through statistical learning. To automate this approach, users first provide high-rate-of-sampling demosntration trajectories of the skill, ideally expressing subtle variation. Demonstration trajectories are aligned using a technique called Dynamic Time Warping <span id=\"citation-0\" data-hover=\"\"><span class=\"citation-number\">[?]</span></span>, which is an algorithmic method to align similar-structural regions in sequential data from one sequence to another. The data points of these temporally aligned demonstration trajectories are clustered into sequential groups across demonstrations. These clusters of robot state data are fitted to learned <em>keyframe distributions</em>, which are used to generate waypoints that the robot follows sequentially to perform a skill. Forming statistical distributions to represent keyframes, as opposed to single points, enables the LfD algorithm to adapt to behavioral restrictions the human operator migth decide to place on the robot.</p>\n<h2>Concept Constrained Learning from Demonstration</h2>\n<p>Intents are global properties of a text document (or user query) that map the document to an assigned goal or desire of the user. They can map to very broad concepts such as ‘weather’, ‘banking’, ‘location search’ or to specific concepts such as ‘get product info’, ‘schedule meeting, etc,. These intents are sometimes called user actions and it is the goal of Bolt to categorize queries into a set number of intents. The following query would be categorized to the given intent:</p>\n<blockquote>\n<p><strong>Query</strong>: What is the shipping information for order #2314?<br>\n<strong>Intent</strong>: get-order-shipping-information  </p>\n</blockquote>\n<h4>Slots</h4>\n<p>Slots are regions or spans within a text document, sometimes overlapping, that map to a specific type of information. They often constitute a semantically loaded region of the text.  An NLP system must correctly detect the right span/region that contains these semantic slots of information. The following date-time phrase provides an example of a slot:</p>\n<blockquote>\n<p><strong>Query</strong>: How many returning customers did I have in [the first quarter of 2015]?<br>\n<strong>Slot Type</strong>: Date-time<br>\n<strong>Extraction Information</strong>: 1/1/2015 - 4/1/2015</p>\n</blockquote>\n<h4>Entities</h4>\n<p>Entities are also regions of text that contain semantic information but often boil down to a single word or compound. They can be thought of as a highly specific slot. Generally, entities encompass names, organizations, locations, and domain specific pieces of information. It is the goal of a named entity recognition system to identify these entities. For example:</p>\n<blockquote>\n<p><strong>Query</strong>: Get me [Winona Snyder’s] most recent order.<br>\n<strong>Entity</strong>: Customer Name = Winona Snyder</p>\n</blockquote>\n<h2>Implementation</h2>\n<h4>Model Generality vs Specificity</h4>\n<p>Often a goal of the design of an NLU system, especially one designed for a targeted domain, is to provide as much generality as possible. This often means that the system’s goal centers around supporting as many users and/or as many use cases as possible with a minimal amount of model generation and methods. The reason being is that the implementation of certain NLP features can be reused and shared. Share models are easier to maintain (no management of devoted models). Additionally, new training data generated by user behavior effectively crowd sourced. For example, in Bolt, the mechanism that determines a user’s intent is shared amongst all users. This way, new data (such as new variations of a similar query) can be incorporated into a newly trained model for which all users share the benefit.</p>\n<p>However, there are certain times when specificity takes precedence over generality. In our case, each one of our Shoppy Bot users has a store with a wide range of products, each with unique names. When parsing a query for slots and entities, an NLU system has to return information that is specific to that user. Avoiding returning information from one user to another is also a requirement as our customers expect their data and analytics to be protected. Bolt employs a fast dictionary/gazetteer algorithm that utilizes distinct data structures specific to each of our users.</p>\n<p>The following outlines three specific implementation details of the Bolt NLU system developed for Shoppy Bot in terms of the intent-slot NLU paradigm.</p>\n<h4>Intent Classification</h4>\n<p>Intent categorization is achieved most commonly through state-of-the-art text classifiers. Bolt uses a discriminative classifier known as a support vector machine. Briefly, support vector machines (SVMs) are classifiers that construct non-probabilistic models represented in a geometric manner. Data is mapped into a geometric space. The different categories or classes of data are separated by a hyperplane optimized for achieving the largest distance between the closest data points of two different categories. The technical details of support vector machines are beyond the scope of this post, but they are the soup du jour for text classifiers (especially for smaller datasets) and are fairly robust against outlier data.\nBolt uses the fantastic library Scikit-learn and its implementation of an SVM. Specifically we use the class <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\">LinearSVC</a>. It supports multi-class classification and scales to larger datasets decently by employing <a href=\"https://www.csie.ntu.edu.tw/~cjlin/liblinear/\">liblinear</a> instead of <a href=\"https://www.csie.ntu.edu.tw/~cjlin/libsvm/\">libsvm</a>. One challenge is that many SVM’s underlying implementations, such as libsvm, are quadratic in their algorithmic complexity which can make datasets >10000 samples highly inefficient. LinearSVC performs well as it does not use any kernel function to turn a dataset that is non-linear into a linearly interpretable dataset, thus dramatically enhancing the algorithmic efficiency.</p>\n<p>Any machine learning technique is powerless without data. Data must be curated in a way that best represents pertinent information about your problem. Bolt’s intent classification challenge is first and foremost a text classification problem. We take a user’s text query and classify that text into an intent category. Determining what type of data you give your machine learning algorithm is a process called feature generation. One of the most common ways to generate features (data tailored for use in a machine learning algorithm) from text is to employ a simple technique known as the ‘bag-of-words’ technique. The frequency (number of occurrences) of all the words for each text category are used as specific values for data points in the geometric space we generate. </p>\n<p>Similar words are used repeatedly for similar user intents. It plays to Bolt’s advantage that queries are often specific to the task at hand, which limits the amount of noise (overlap of categories) and number of outliers (single data points invading deep into the region of a different category). This means that the distinction between one category and another in our geometric space is sharp. I won’t go too deep into how SVM’s work, but I suggest Wikipedia as a good starting point.</p>\n<p><figure><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 392px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ee94b5d9c99d348b59a03549a5ce621b/0acb4/hyperplane.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 95.57522123893806%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE3ElEQVQ4y2NgAIJJHT3iNY01wq2tzfxdbW18yLgTiDtAdHs7gt3WJtDd3i42Y+pUzmmTJjExQEFfdzcDQ9vsPu6G/hYZBhJAX1s708SeXrbVq1YyzZw2jWvW9Okc61evZgRLrlm4VNi3Jr7AJj8gP7oqXQQs1jOHtba5jrO3o5W9uW4qZ1XpLK7G2l6OzrZ2jo7Wbrb25nb+1sZ2gZamVpa25mY2oMt4JvX3C/f39gowzGzrFUgoyxB1Kgk7YlsSfNWpLKw5uT5P7M6szcwVtR3c//8zgL10/rIDS19vCfuyZSksHW2VfNOnp/BOm1LB2tHSwdne0swOMriro0OQoaG1nhekoXBKnZpDZfgJi+KAjxaF/vNg3ovy+qLq5/DY1cnimky4439mkFhK0GfdYNd7/uhB0dXZycXQ197Bk1aXzw4SCGpLtwUaet2yOOCFdVFwNUgs1PuBup/jo4wI9328wU53xYNdn5rH+d0PDXJ55uztcMMKpCY64DTYF0AX8jL0tLfz9HZ0MZc3VoJd6t2UlG5XGfYQaOhDu5KwAJCYj/NxXQvzS172gf+FswLuc61ZUc6ZEvzROdzjSaqn3QUOkJrmhkksYBd2AQ1cXl7K2ldfyw1zuldjfI9tRegzy+LAy65VwRq2uv+Vtli5SGXZHQy1t3lgFupxwc3Z8rgssne7uzrZujs7ORmmNNRzM/z/D3byDwcLu/cmBr4gtkd97Hqb8pAXNiUBOw18Llne07U3nGLdEmjg8lUtyOWQu7f9PS0fhwduCUHvwC7saOvlBLqQjQFoGPMTbzfLC872Sj8drHQvOFpKgBRkdhWoOtfFHrcuC35pU+41CSRmYvdcNdT9mkFs8BlpEN/X8YqGj/0tc4iXJ/L1dHczMqzs7+N56WKXeszHA+yF9/HhnG9c7ML/m+l7TstwLnCsibplUR7w2D6jsLuW4T9XQtp8EX+Xi1Go8fsf6OUOno72dkaGiQ0NPGrXHzK9crH3uxrsr34/wNfivbNpyA7vbK9c/3+WXi0xOQ4lvi8sciPeu6SVZIK0JyetlAMZUla4jBESfm0s3Z1dXGCzqyZO4jyXGMv71Mbc95eLrdJ7S+PeD3b6Oo8cA1232FcEgdT4V0dNt6kKempR6nvaujBMBSRW2lfIgoiQLpbOjg6IgdOqKrlA4XjPw9n4i5GO8Etbc9Uzmto8YI84ajp9MjdKWNRYLOjSHL/euiLkDTDRb06uL+VbP38ZBzxBd3RwAmOYFcxZVF/Hkrp4Kff1AG+Fd8a6YiCxXx4OUl9sLVyeWZhZ1+WEs4HE4iYXqzo3xpyyLAt6Y1MS7AZ2ZWcNOEMADeMBuhJS6swrLmSumDVb6IuDle0tQ11wWnxnZ2H40txQYZehLtiw8NIQsPeCerNcHOoiX9tWhtaBXTapmw9qIDfQy5DSZnp5OXPDlKkib61N1a6YGXGh58+DPp6MU4ElhHGxLzgfe7UnVTrWRx0AO2bGDI7JEydwtre1gfUBaQaG3v5+5t6WFnHURADBuIBne9Jkl5Y4IxB74uR+YaDrwD7r6epiYCgvLASVaRLrGupZO2trWbp7elgmTZzI1lBfz9XW2soDLKF5gDaD6caOZr4zFStZ0/vKVKN78u1vN2xjaW5tFunu6AAHCTAbMwAAMnXbuLftc78AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"hyperplane\"\n        title=\"hyperplane\"\n        src=\"/static/ee94b5d9c99d348b59a03549a5ce621b/0acb4/hyperplane.png\"\n        srcset=\"/static/ee94b5d9c99d348b59a03549a5ce621b/2519b/hyperplane.png 113w,\n/static/ee94b5d9c99d348b59a03549a5ce621b/3684f/hyperplane.png 225w,\n/static/ee94b5d9c99d348b59a03549a5ce621b/0acb4/hyperplane.png 392w\"\n        sizes=\"(max-width: 392px) 100vw, 392px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span><figcaption>Hyperplane separating two categories</figcaption></figure>\n<em>A hyperplane (which is a standard flat plane in three dimensions) separating two categories distinguished by red and blue spheres. <a href=\"https://i.stack.imgur.com/zeRTm.png\">Source</a></em></p>\n<h4>Slot Detection</h4>\n<p>Slot detection sometimes blurs the line between entity parsing and recognition. It can help to think of named entity recognition (NER), where one parses a product name, city and state etc., as a subset of slot detection. Slots can be a feature of the entire piece of text being analyzed or a localized span of text. One example of a slot that spans the entirety of a user query would be plurality. For example, if the user asks, “Who is my top customer?”, Bolt is able to recognize that the person is asking for only one customer, without needing any explicit number to exist in the query. These results are passed back to Shoppy Bot where a response is sent to the user with the results for one customer. </p>\n<p>Bolt actually uses a binary classifier to determine the query’s plurality. We use a similar ‘bag of words’ technique as the intent classifier but also employ a technique that emphasizes particular features. The emphasized features are words associated with plurality. For example, verb conjugation plays an obvious role in identifying whether or not the query is asking for plural results. The verbs ‘is/are’, ‘was/were’ greatly increase the accuracy of the classification model without the need for large amounts of data. It is a case where smart feature engineering helped defeat a lack of data on our end. As the slot detection of plurality is independent of any specific user, it is a generalizable model.</p>\n<h4>Named Entity Recognition</h4>\n<p>Named entity recognition is the probably the most well-known aspect of information retrieval and slot detection in terms of NLP. Shoppy Bot users each have a large set of product names associated with their Shopify store. These “named entities” must be identified and parsed specific to the user. Bolt employs a set of data structures and a specialized string comparison algorithm to successfully parse product names from a user’s query.</p>\n<p>The data structure that Bolt’s gazetteer uses is called a trie. In this scenario, a trie is an ordered tree structure that stores strings compactly, where each node of the tree is an object or structure that stores the current letter, potentially a word, and references or pointers to the next node. The idea is that in traversing a branch of the trie, you slowly build up a word letter by letter. Words that share the same prefix will start along the same branch.</p>\n<p><figure><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 450px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/037763317989df7427c7fac152dedcb9/6a068/search_trie.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 75.2212389380531%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd1UigD/xAAWEAEBAQAAAAAAAAAAAAAAAAAQEQD/2gAIAQEAAQUCZof/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAZEAEBAQADAAAAAAAAAAAAAAABABExQXH/2gAIAQEAAT8hXSOe4dkXqy//2gAMAwEAAgADAAAAEDQP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxABAQADAQEBAAAAAAAAAAAAAREAITFBgZH/2gAIAQEAAT8Q5jC9qY4BW+C9/cCp4xxBojEuW04gc3rAH3bn/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"search trie\"\n        title=\"search trie\"\n        src=\"/static/037763317989df7427c7fac152dedcb9/20e5d/search_trie.jpg\"\n        srcset=\"/static/037763317989df7427c7fac152dedcb9/30b1b/search_trie.jpg 113w,\n/static/037763317989df7427c7fac152dedcb9/863e1/search_trie.jpg 225w,\n/static/037763317989df7427c7fac152dedcb9/20e5d/search_trie.jpg 450w,\n/static/037763317989df7427c7fac152dedcb9/512c0/search_trie.jpg 675w,\n/static/037763317989df7427c7fac152dedcb9/8e1fc/search_trie.jpg 900w,\n/static/037763317989df7427c7fac152dedcb9/6a068/search_trie.jpg 960w\"\n        sizes=\"(max-width: 450px) 100vw, 450px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span><figcaption>String search trie</figcaption></figure>\n<em><a href=\"http://images.slideplayer.com/32/9814580/slides/slide_5.jpg\">Source</a></em></p>\n<p>This data structure allows one to check if a word is in a dictionary extremely quickly but also allows for additional algorithms to function during the search process. Hash lookups for words are generally the fastest mechanism for dictionary lookups. However, if you want to perform string similarity comparisons while searching for a word in a dictionary at the same time, the search trie is your best bet. This allows for robust dictionary lookup of words pulled from the query to see if they match (or are close to matching) the words stored in the trie. Ultimately this is a very robust way to perform fuzzy dictionary lookups. </p>\n<p>The string similarity mechanism Bolt’s gazetteer uses is the <a href=\"https://people.cs.pitt.edu/~kirk/cs1501/Pruhs/Spring2006/assignments/editdistance/Levenshtein%20Distance.htm\">Levenshtein</a> string similarity algorithm. Briefly, it is an algorithm that outputs an integer value called the string distance representing the number of insertions, switches, and deletions it takes to convert one word into another. After removing common words and certain specialty words from the query, the remaining words are grouped in a number of combinations. These combinations of words are each run through the gazetteer’s search algorithm to find matches within a certain Levenshtein string distance. The algorithm traverses down the trie building test words from the letters along the nodes in the path. The algorithm can dynamically append or remove new letters from the current current trie word so that the Levenshtein algorithm only has to readjust for the new letter in its comparison with the test word from the query. Thus we are not constantly performing and reperforming the entire Levenshtein algorithm for every word in the trie.</p>\n<p>One additional step Bolt takes to ensure robustness is to add n-grams and skip-grams of the product names into the trie. For example, ‘sally sells sea shells’ as n-grams of length 3 (tri-grams) would be split into ‘sally sells sea’ and ‘sells sea shells’. Skip-grams of length skip distance 1 would result in ‘sally sea shells’ and ‘sally sells shells’. The purpose of these n-grams and skip grams is to account for the different ways a user might express a product name. Perhaps they don’t type every single word if it is a long product name.</p>\n<h4>The Big Picture</h4>\n<p>Bolt first classifies the user’s query to an intent. Each intent is associated with a set of possible slots/entities that can be parsed for that intent. Those slots/entities are then parsed. In summary, Bolt generally operates with the following procedure:</p>\n<ol>\n<li>\n<p>Classify User Query to Intent:</p>\n<blockquote>\n<p><strong>Query</strong>: What is the shipping information for order #2314?<br>\n<strong>Intent</strong>: get-order-shipping-information<br>\n<strong>Associated Slots/Entities</strong>: Order Number  </p>\n</blockquote>\n</li>\n<li>\n<p>Perform slot/entity detection</p>\n<blockquote>\n<p><strong>Query</strong>: What is the shipping information for order #2314?<br>\n<strong>Entities</strong>: Order Number = #2314</p>\n</blockquote>\n</li>\n<li>Return information to Shoppy Bot server</li>\n</ol>\n<h2>Conclusion</h2>\n<p>This post provided a fairly indepth overview of some of the theory and implementation details that go into making the Bolt NLU system function. Natural language understanding is exploding and becoming more advanced day by day. The intent-slot paradigm for NLU is a robust and relatively simplistic approach to NLU that can be achieved fairly easily with some simple and clever algorithms and engineering. With this approach, we’re able to provide an NLU system that outperforms other cloud-based solutions on the market, and offer a more sophisticated chatbot experience.</p>\n<p><ol><li><b>Robust Robot Learning from Demonstration and Skill Repair Using Conceptual Constraints</b> <br>Mueller, C., Venicx, J. and Hayes, B., 2018. 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6029--6036. </li><li><b>Recent advances in robot learning from demonstration</b> <br>Ravichandar, H., Polydoros, A.S., Chernova, S. and Billard, A., 2020. Annual Review of Control, Robotics, and Autonomous Systems, Vol 3. Annual Reviews.</li><li><b>Keyframe-based learning from demonstration</b> <br>Akgun, B., Cakmak, M., Jiang, K. and Thomaz, A.L., 2012. International Journal of Social Robotics, Vol 4(4), pp. 343--355. Springer.</li></ol></bibliography></p>","fields":{"slug":"/research/cc-lfd/"},"frontmatter":{"authors":["Carl Mueller"],"date":"October 26, 2018","title":"Concept Constrained Learning from Demonstration","coverDesc":"Sawyer hoping to avoid spilling coffee...","featuredImage":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAkABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAMEBQL/xAAXAQEAAwAAAAAAAAAAAAAAAAABAAID/9oADAMBAAIQAxAAAAGG/i6I8oEOJ69kvmrBrtSGOkYJ/8QAHxAAAgICAQUAAAAAAAAAAAAAAQIDEQASBBMhIiMx/9oACAEBAAEFAurrgPhyKV1+I3rkouzClkGhcglDcQbaTjtuRlds/8QAFxEAAwEAAAAAAAAAAAAAAAAAEBEgIf/aAAgBAwEBPwFDY//EABgRAAIDAAAAAAAAAAAAAAAAAAARARAh/9oACAECAQE/ARmDi//EACEQAAECBQUBAAAAAAAAAAAAAAEAEQIQITFhAxIgQXGx/9oACAEBAAY/AmIdReIDtpROqWVmwEx06/ZERXwgCCyO2o4f/8QAHBABAAMBAAMBAAAAAAAAAAAAAQARITFBUfCB/9oACAEBAAE/IduI3ZN8+3AgrG69zRMq+xS9dFX+xqS+lzYpV4RLJg+VGlcjQJbcHV8QlBTYAsCWrYmz/9oADAMBAAIAAwAAABBLMDwL7//EABcRAQEBAQAAAAAAAAAAAAAAAAEAERD/2gAIAQMBAT8QcG2SICxnn//EABgRAAMBAQAAAAAAAAAAAAAAAAABEBEx/9oACAECAQE/ENjYELh//8QAHhABAQADAQACAwAAAAAAAAAAAREAIUExYXGBkdH/2gAIAQEAAT8QprlaA7DmMyx8Uu0YIsqTBp5iQBV2DWjAGcEOgTBBQAFXzBJm1AN8v9y0BKlELVTTBZAlQSwvmOd70UfjBHXjODQfoyrAIbsvMkR+cLD7HCaTP//Z","aspectRatio":0.56,"src":"/static/ae38715e04c7da54e072d869a8449e29/58f33/Placement.jpg","srcSet":"/static/ae38715e04c7da54e072d869a8449e29/0caaa/Placement.jpg 140w,\n/static/ae38715e04c7da54e072d869a8449e29/3e0e0/Placement.jpg 280w,\n/static/ae38715e04c7da54e072d869a8449e29/58f33/Placement.jpg 561w,\n/static/ae38715e04c7da54e072d869a8449e29/7b79b/Placement.jpg 841w,\n/static/ae38715e04c7da54e072d869a8449e29/34847/Placement.jpg 1121w,\n/static/ae38715e04c7da54e072d869a8449e29/2eecf/Placement.jpg 1256w","sizes":"(max-width: 561px) 100vw, 561px","maxHeight":1000,"maxWidth":561}}}}}},"pageContext":{"slug":"/research/cc-lfd/"}},"staticQueryHashes":["3048952670","4224293195"]}